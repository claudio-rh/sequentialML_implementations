{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8466efb-b6c5-4ef0-bd36-071bc4828b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoselm.oselm import OSELMRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = \"../datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35123f88-42fc-449f-8c15-0d49c04168ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeferradOSELM(hidden,X,y,f,shuffle_):\n",
    "    oselmr = OSELMRegressor(n_hidden=hidden, activation_func=f, random_state=123)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=shuffle_)\n",
    "    n_batch = 1\n",
    "    \n",
    "    batches_x = [X_train[:hidden]] + [[x_i] for x_i in X_train[hidden:]]\n",
    "    batches_y = [y_train[:hidden]] + [[y_i] for y_i in y_train[hidden:]]\n",
    "    for b_x, b_y in zip(batches_x, batches_y):\n",
    "        if len(batches_x) > 0:\n",
    "            oselmr.fit(b_x, b_y)\n",
    "    return oselmr,X_test,y_test\n",
    "\n",
    "def metrics(true,pred):\n",
    "    squareDeviation = computeSquareDeviation(pred, true)\n",
    "    nmrse = np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(pred)\n",
    "    return nmrse\n",
    "    \n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05bf3a7-2c3b-44bb-800f-8005d50fa208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 5.593715399999994\n",
      "NRMSE promedio 0.7922285768964041\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 14.408046799999994\n",
      "NRMSE promedio 0.7873130758253564\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 40.191344799999996\n",
      "NRMSE promedio 0.72447787594832\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 5.5566240000000136\n",
      "NRMSE promedio 0.7023035523168265\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 13.807851499999998\n",
      "NRMSE promedio 0.70408017993319\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 42.653465900000015\n",
      "NRMSE promedio 0.6163212395377745\n"
     ]
    }
   ],
   "source": [
    "#NYC DATASET\n",
    "\n",
    "dataset = \"nyc_taxi.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "\n",
    "\n",
    "raw[\"hour\"] = [t.hour for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"minute\"] = [t.minute for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw['year'] = [t.year for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw.drop(['timestamp'],inplace=True,axis=1)\n",
    "\n",
    "data = raw.to_numpy()\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21755050-e3aa-4534-b97f-de77a9b669d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 0.14938730000000078\n",
      "NRMSE promedio 0.01939045486401937\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 0.35263349999999605\n",
      "NRMSE promedio 0.01735231617041292\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 0.8289634999999862\n",
      "NRMSE promedio 0.006698356856153685\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 0.14216880000000742\n",
      "NRMSE promedio 0.024083205289077265\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 0.30531519999999546\n",
      "NRMSE promedio 0.01620185739224892\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 0.7247572999999932\n",
      "NRMSE promedio 0.018833378858127945\n"
     ]
    }
   ],
   "source": [
    "#COVID DATASET\n",
    "dataset = \"covid_chile.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.date)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.date)]\n",
    "\n",
    "raw.drop([\"date\"],inplace=True,axis=1)\n",
    "\n",
    "data = raw.to_numpy()\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4ac41b-8333-45fc-ad33-5ffc40c8f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 4.152931200000012\n",
      "NRMSE promedio 1.2901061290497853\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 11.46947449999999\n",
      "NRMSE promedio 1.1281020282118035\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 33.83839820000003\n",
      "NRMSE promedio 0.9901728559987408\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 4.348999400000025\n",
      "NRMSE promedio 1.5292528110045043\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 11.769761399999993\n",
      "NRMSE promedio 1.2085651714822394\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 33.280370800000014\n",
      "NRMSE promedio 1.0345458607633518\n"
     ]
    }
   ],
   "source": [
    "#BIKE DATASET\n",
    "dataset = \"train_bikeDemand.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw.drop(raw.columns[0], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "raw = raw[['count','holiday', 'workingday', 'temp', 'atemp', 'humidity', 'windspeed', 'season_1', 'season_2', 'season_3', 'season_4', 'weather_1', 'weather_2', 'weather_3', 'weather_4', 'hour', 'day', 'month', 'year']]\n",
    "\n",
    "data = raw.to_numpy()\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec3e1f4-3a8b-4675-96ee-5e6ad8d17997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 1.5410825000001296\n",
      "NRMSE promedio 1.6689360991267652\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 3.8727086999999756\n",
      "NRMSE promedio 1.021638663303797\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 11.30968689999986\n",
      "NRMSE promedio 1.6255567929494565\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 1.4044375000000855\n",
      "NRMSE promedio 7.972177789560509\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 3.844607399999859\n",
      "NRMSE promedio 6.079421319479798\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 10.745680500000162\n",
      "NRMSE promedio 1.4240648370129514\n"
     ]
    }
   ],
   "source": [
    "#REC CENTER\n",
    "\n",
    "dataset = \"rec-center-hourly.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1,2])\n",
    "\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "\n",
    "raw.drop(['timestamp'],inplace=True,axis=1)\n",
    "\n",
    "data = raw.to_numpy(dtype= 'float')\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",False)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",False)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d1e312-6926-48cb-8af6-5e298c08f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 3.191766300000154\n",
      "NRMSE promedio 1.1067013990753456\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 8.45430999999985\n",
      "NRMSE promedio 0.9129759972917441\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 25.25314419999995\n",
      "NRMSE promedio 0.8223211823321848\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 3.1322018000000753\n",
      "NRMSE promedio 1.0306106000088575\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 8.418966999999839\n",
      "NRMSE promedio 1.0144162798403835\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 23.854961399999866\n",
      "NRMSE promedio 0.8395106320168128\n"
     ]
    }
   ],
   "source": [
    "#AVOCADOS\n",
    "\n",
    "avocados = pd.read_csv(path + 'filtered_avocados.csv')\n",
    "new_columns = pd.DataFrame(avocados[\"Date\"].str.split('-').tolist(), columns = ['yr', 'month', 'day'])\n",
    "\n",
    "# Change data type of new columns from str to int32\n",
    "new_columns[\"day\"] = new_columns[\"day\"].astype(np.int32)\n",
    "new_columns[\"month\"] = new_columns[\"month\"].astype(np.int32)\n",
    "# Attach new columns\n",
    "avocados[\"day\"] = new_columns[\"day\"]\n",
    "avocados[\"month\"] = new_columns[\"month\"]\n",
    "avocados[\"type\"]=pd.Categorical(avocados[\"type\"])\n",
    "avocados[\"region\"]=pd.Categorical(avocados[\"region\"])\n",
    "df_type = pd.get_dummies(avocados['type'], prefix = 'category')\n",
    "df_region = pd.get_dummies(avocados['region'], prefix = 'category')\n",
    "\n",
    "# Drop Date, type and region\n",
    "del avocados[\"Date\"]\n",
    "del avocados[\"type\"]\n",
    "del avocados[\"region\"]\n",
    "\n",
    "# Attach the one-hot encodings columns to other integer ones\n",
    "avocados_cleaned=pd.concat([avocados, df_type, df_region], axis=1, sort=False)\n",
    "\n",
    "\n",
    "data = avocados_cleaned.to_numpy()\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",False)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred \n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cff7369-74ef-49ac-b445-e11da4c3e8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5749400</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6590300</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5405900</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11688800</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313.70</td>\n",
       "      <td>315.72</td>\n",
       "      <td>307.30</td>\n",
       "      <td>621.43</td>\n",
       "      <td>8824000</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low   Close    Volume  year\n",
       "0  331.27  333.87  329.08  666.45   5749400  2012\n",
       "1  329.83  330.75  326.89  657.21   6590300  2012\n",
       "2  328.34  328.77  323.68  648.24   5405900  2012\n",
       "3  322.04  322.29  309.46  620.76  11688800  2012\n",
       "4  313.70  315.72  307.30  621.43   8824000  2012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 0.447335700000167\n",
      "NRMSE promedio 0.024017578450759084\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 1.2265127999999095\n",
      "NRMSE promedio 0.01935443452306518\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 3.3178928999998334\n",
      "NRMSE promedio 0.036004628695201414\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 0.41161299999998846\n",
      "NRMSE promedio 0.024750563963725915\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 1.0006677000001218\n",
      "NRMSE promedio 0.023457743168134752\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 2.8644308000000365\n",
      "NRMSE promedio 0.025959077360333968\n"
     ]
    }
   ],
   "source": [
    "#GOOGLE DATASET\n",
    "dataset = \"Google_Stock_Price_Train.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw['year'] = [t.year for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw.drop(['Date',\"day\",\"month\"],inplace=True,axis=1)\n",
    "\n",
    "raw['Volume'] = raw['Volume'].str.replace(',', '')\n",
    "raw['Close'] = raw['Close'].str.replace(',', '')\n",
    "\n",
    "display(raw.head())\n",
    "\n",
    "data = raw.to_numpy(dtype = 'float')\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ff451f-a0a6-4696-9b03-5cb1865f12ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 1.6273573999999371\n",
      "NRMSE promedio 0.8988357967758727\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 4.441134899999952\n",
      "NRMSE promedio 0.8244244843876786\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 12.377235400000018\n",
      "NRMSE promedio 0.8593665062906908\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 1.459498100000019\n",
      "NRMSE promedio 0.884433172540677\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 3.901646600000049\n",
      "NRMSE promedio 0.8003851921805201\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 11.336138500000061\n",
      "NRMSE promedio 0.8587490110409793\n"
     ]
    }
   ],
   "source": [
    "#AbALONE DATASET\n",
    "\n",
    "dataset = \"Abalone.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "map = {'M':0,'F':1,'I':2}\n",
    "raw = raw.replace({'sex':map})\n",
    "raw = raw[[\"rings\",\"length\",\"diameter\",\"height\",\"weight.w\",\"weight.s\",\"weight.v\",\"weight.sh\",\"sex\"]]\n",
    "\n",
    "\n",
    "data = raw.to_numpy(dtype = 'float')\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9ffc7f-17dd-4df1-a072-4153769f5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neurons = 25 SIGMOID\n",
      "Tiempo promedio 0.14580369999998766\n",
      "NRMSE promedio 0.43070430568884294\n",
      "\n",
      "Neurons = 50 SIGMOID\n",
      "Tiempo promedio 0.32222279999996317\n",
      "NRMSE promedio 0.37911965524659774\n",
      "\n",
      "Neurons = 100 SIGMOID\n",
      "Tiempo promedio 0.7691647999999986\n",
      "NRMSE promedio 0.40005520724824606\n",
      "\n",
      "Neurons = 25 RELU\n",
      "Tiempo promedio 0.13280009999994036\n",
      "NRMSE promedio 0.3958405627257386\n",
      "\n",
      "Neurons = 50 RELU\n",
      "Tiempo promedio 0.3065317000000505\n",
      "NRMSE promedio 0.4266070619510049\n",
      "\n",
      "Neurons = 100 RELU\n",
      "Tiempo promedio 0.7204800000001796\n",
      "NRMSE promedio 0.47167926204901095\n"
     ]
    }
   ],
   "source": [
    "dataset = \"auto-mpg.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw.drop([\"car name\"],inplace=True,axis=1)\n",
    "data = raw.to_numpy(dtype = 'float')\n",
    "\n",
    "y = data[:,:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"sigmoid\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"SIGMOID\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))\n",
    "\n",
    "    \n",
    "    \n",
    "for j in [25,50,100]:\n",
    "    t_ = []\n",
    "    errores = []\n",
    "    for i in range(1):\n",
    "        start = timer()\n",
    "        model,X_test,y_test = LeferradOSELM(j,X,y,\"relu\",True)\n",
    "        end = timer()\n",
    "        t_.append(end - start)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions = pred\n",
    "        target = y_test\n",
    "        errores.append(metrics(target,predictions))\n",
    "    print(\"\\nNeurons =\",j,\"RELU\")\n",
    "    print(\"Tiempo promedio\",np.mean(t_))\n",
    "    print(\"NRMSE promedio\",np.mean(errores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef50f9-65af-43e6-b711-68c8303affb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
