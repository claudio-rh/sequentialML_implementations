{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3b7b4e7-8e19-4ab7-9db1-39078253d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.activations import relu\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Dense\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# Resets \n",
    "tf.compat.v1.reset_default_graph()\n",
    "path = '../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ebb57cc-c42c-4e80-a8a4-f4dce6bd009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AndreKeras(X_train,y_train,X_test,y_test,steps,batch,neurons,act,use_earlyStopFunction):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,activation=act , input_shape=(X_train.shape[1],)) )\n",
    "    model.add(Dense(neurons,activation=act))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "\n",
    "    epochs = steps\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    opt = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "\n",
    "    batch_size = batch\n",
    "    \n",
    "    if(use_earlyStopFunction):\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 1, epochs = steps,callbacks = [callback],verbose = False)\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = 1, epochs = steps,verbose = False)\n",
    "        \n",
    "    return model,history    \n",
    "\n",
    "def computeSquareDeviation(predictions, truth):\n",
    "  squareDeviation = np.square(predictions-truth)\n",
    "  return squareDeviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00bc834c-ce0f-4fc4-8704-a846ea756a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NYC DATASET\n",
    "\n",
    "dataset = \"nyc_taxi.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "\n",
    "\n",
    "raw[\"hour\"] = [t.hour for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"minute\"] = [t.minute for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw['year'] = [t.year for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw.drop(['timestamp'],inplace=True,axis=1)\n",
    "\n",
    "data = raw.to_numpy()\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = True\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3275672b-ab88-4972-afc8-87bccc4f5251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "relu 25\n",
      "Time 327.1535539000006\n",
      "NRMSE 0.02419597331328203\n",
      "\n",
      "\n",
      "relu 50\n",
      "Time 351.16153719999966\n",
      "NRMSE 0.020679875648122157\n",
      "\n",
      "\n",
      "relu 100\n",
      "Time 345.9948610000001\n",
      "NRMSE 0.02529713798277923\n",
      "\n",
      "\n",
      "sigmoid 25\n",
      "Time 344.5754401000004\n",
      "NRMSE 0.02577481964237529\n",
      "\n",
      "\n",
      "sigmoid 50\n",
      "Time 355.64550919999965\n",
      "NRMSE 0.021857556947521107\n",
      "\n",
      "\n",
      "sigmoid 100\n",
      "Time 365.36542980000013\n",
      "NRMSE 0.031717386538884576\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Google_Stock_Price_Train.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw['year'] = [t.year for t in pd.DatetimeIndex(raw.Date)]\n",
    "raw.drop(['Date',\"day\",\"month\"],inplace=True,axis=1)\n",
    "\n",
    "raw['Volume'] = raw['Volume'].str.replace(',', '')\n",
    "raw['Close'] = raw['Close'].str.replace(',', '')\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = False\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b7c3f27-abbf-4406-8dd5-063a47639b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rings</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>weight.w</th>\n",
       "      <th>weight.s</th>\n",
       "      <th>weight.v</th>\n",
       "      <th>weight.sh</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.120</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rings  length  diameter  height  weight.w  weight.s  weight.v  weight.sh  \\\n",
       "0      7   0.350     0.265   0.090    0.2255    0.0995    0.0485      0.070   \n",
       "1      9   0.530     0.420   0.135    0.6770    0.2565    0.1415      0.210   \n",
       "2     10   0.440     0.365   0.125    0.5160    0.2155    0.1140      0.155   \n",
       "3      7   0.330     0.255   0.080    0.2050    0.0895    0.0395      0.055   \n",
       "4      8   0.425     0.300   0.095    0.3515    0.1410    0.0775      0.120   \n",
       "\n",
       "   sex  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    2  \n",
       "4    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = \"Abalone.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "map = {'M':0,'F':1,'I':2}\n",
    "raw = raw.replace({'sex':map})\n",
    "\n",
    "raw = raw.reindex(columns=['rings','length','diameter','height','weight.w','weight.s','weight.v','weight.sh','sex'])\n",
    "display(raw.head())\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = True\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c674a-12fd-480b-9b12-a1a005f57a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIKE DATASET\n",
    "dataset = \"train_bikeDemand.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw.drop(raw.columns[0], axis=1,inplace=True)\n",
    "cols = list(raw.columns)\n",
    "a, b = cols.index('holiday'), cols.index('count')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "raw = raw[cols]\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "\n",
    "\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = True\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fec7ff3d-5ac6-4642-a402-17049b110105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_energy_consumption</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kw_energy_consumption  day  month\n",
       "0                   21.2    2      7\n",
       "1                   16.4    2      7\n",
       "2                    4.7    2      7\n",
       "3                    4.7    2      7\n",
       "4                    4.6    2      7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "relu 25\n",
      "Time 19.32884860000013\n",
      "NRMSE 6.975757677857954\n",
      "\n",
      "\n",
      "relu 50\n",
      "Time 12.050458899999285\n",
      "NRMSE 7.517476632550677\n",
      "\n",
      "\n",
      "relu 100\n",
      "Time 15.129576200000884\n",
      "NRMSE 8.465183858235623\n",
      "\n",
      "\n",
      "sigmoid 25\n",
      "Time 42.062565500000346\n",
      "NRMSE 7.85478600919484\n",
      "\n",
      "\n",
      "sigmoid 50\n",
      "Time 28.912588600000163\n",
      "NRMSE 8.452301120121426\n",
      "\n",
      "\n",
      "sigmoid 100\n",
      "Time 29.253272699999798\n",
      "NRMSE 8.41170098252783\n"
     ]
    }
   ],
   "source": [
    "#REC CENTER DATASET\n",
    "dataset = \"rec-center-hourly.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1,2])\n",
    "\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.timestamp)]\n",
    "raw.drop([\"timestamp\"],inplace=True,axis=1)\n",
    "display(raw.head())\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = True\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f626454c-5a31-4e5c-bcd4-ab6a6bfef85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confirmed  day  month  year  deaths  recovered\n",
       "0          0   23      1  2020       0          0\n",
       "1          0   24      1  2020       0          0\n",
       "2          0   25      1  2020       0          0\n",
       "3          0   26      1  2020       0          0\n",
       "4          0   27      1  2020       0          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "relu 25\n",
      "Time 49.473234400000365\n",
      "NRMSE 0.00958055511724152\n",
      "\n",
      "\n",
      "relu 50\n",
      "Time 49.12855010000021\n",
      "NRMSE 0.010322786873624503\n",
      "\n",
      "\n",
      "relu 100\n",
      "Time 50.8849252\n",
      "NRMSE 0.010501529710550636\n",
      "\n",
      "\n",
      "sigmoid 25\n",
      "Time 49.34387989999959\n",
      "NRMSE 0.037716444029695886\n",
      "\n",
      "\n",
      "sigmoid 50\n",
      "Time 48.82452039999953\n",
      "NRMSE 0.05611927117248238\n",
      "\n",
      "\n",
      "sigmoid 100\n",
      "Time 49.037908099999186\n",
      "NRMSE 0.07506050194481481\n"
     ]
    }
   ],
   "source": [
    "#COVID DATASET\n",
    "dataset = \"covid_chile.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw[\"day\"] = [t.day for t in pd.DatetimeIndex(raw.date)]\n",
    "raw[\"month\"] = [t.month for t in pd.DatetimeIndex(raw.date)]\n",
    "raw['year'] = [t.year for t in pd.DatetimeIndex(raw.date)]\n",
    "raw.drop([\"date\"],inplace=True,axis=1)\n",
    "raw = raw.reindex(columns=['confirmed','day','month','year','deaths','recovered'])\n",
    "display(raw.head())\n",
    "\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = False\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8042b7a3-d0a6-49b7-92a9-5fd198927f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVOCADOS\n",
    "\n",
    "avocados = pd.read_csv(path + 'filtered_avocados.csv')\n",
    "new_columns = pd.DataFrame(avocados[\"Date\"].str.split('-').tolist(), columns = ['yr', 'month', 'day'])\n",
    "\n",
    "# Change data type of new columns from str to int32\n",
    "new_columns[\"day\"] = new_columns[\"day\"].astype(np.int32)\n",
    "new_columns[\"month\"] = new_columns[\"month\"].astype(np.int32)\n",
    "# Attach new columns\n",
    "avocados[\"day\"] = new_columns[\"day\"]\n",
    "avocados[\"month\"] = new_columns[\"month\"]\n",
    "avocados[\"type\"]=pd.Categorical(avocados[\"type\"])\n",
    "avocados[\"region\"]=pd.Categorical(avocados[\"region\"])\n",
    "df_type = pd.get_dummies(avocados['type'], prefix = 'category')\n",
    "df_region = pd.get_dummies(avocados['region'], prefix = 'category')\n",
    "\n",
    "# Drop Date, type and region\n",
    "del avocados[\"Date\"]\n",
    "del avocados[\"type\"]\n",
    "del avocados[\"region\"]\n",
    "\n",
    "# Attach the one-hot encodings columns to other integer ones\n",
    "avocados_cleaned=pd.concat([avocados, df_type, df_region], axis=1, sort=False)\n",
    "\n",
    "# Shuffle data using the pandas function sample, with fraction as 1 since we want all data \n",
    "avocados = avocados_cleaned.sample(frac=1)\n",
    "# Converto to numpy array\n",
    "avocados = avocados.to_numpy()\n",
    "\n",
    "X = avocados[:,1:]\n",
    "y = avocados[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = True\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb7a9b2-effa-44ff-ac06-77c711237ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  15.0          8         350.0         165    3693          11.5   \n",
       "1  18.0          8         318.0         150    3436          11.0   \n",
       "2  16.0          8         304.0         150    3433          12.0   \n",
       "3  17.0          8         302.0         140    3449          10.5   \n",
       "4  15.0          8         429.0         198    4341          10.0   \n",
       "\n",
       "   model year  origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "relu 25\n",
      "Time 38.126587999999174\n",
      "NRMSE 0.40084193740754476\n",
      "\n",
      "\n",
      "relu 50\n",
      "Time 39.37913870000011\n",
      "NRMSE 0.4392796104390117\n",
      "\n",
      "\n",
      "relu 100\n",
      "Time 39.87838269999884\n",
      "NRMSE 0.4365824832264944\n",
      "\n",
      "\n",
      "sigmoid 25\n",
      "Time 39.05691210000077\n",
      "NRMSE 0.3713614534410912\n",
      "\n",
      "\n",
      "sigmoid 50\n",
      "Time 39.83130980000169\n",
      "NRMSE 0.37819787885129647\n",
      "\n",
      "\n",
      "sigmoid 100\n",
      "Time 41.003256600000896\n",
      "NRMSE 0.36774535782274065\n"
     ]
    }
   ],
   "source": [
    "dataset = \"auto-mpg.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "raw.drop([\"car name\"],inplace=True,axis=1)\n",
    "display(raw.head())\n",
    "\n",
    "data = raw.to_numpy(dtype='float')\n",
    "X = data[:,1:]\n",
    "y = data[:,:1]\n",
    "\n",
    "means = np.mean(y,axis=0)\n",
    "stds = np.std(y,axis=0)\n",
    "y = (y-means)/stds\n",
    "\n",
    "std_Ys = stds[0]\n",
    "mean_Ys = means[0]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123,shuffle = True)\n",
    "\n",
    "\n",
    "batch = 1\n",
    "steps = int(len(X_train) / batch)\n",
    "\n",
    "use_earlyStopFunction = False\n",
    "\n",
    "for f in [\"relu\",\"sigmoid\"]:\n",
    "    for n_ in [25,50,100]:\n",
    "        start = timer()\n",
    "        model_ ,history_ = AndreKeras(X_train,y_train,X_test,y_test,steps,batch,n_,f,use_earlyStopFunction)\n",
    "        end = timer()\n",
    "        t_ = end - start\n",
    "        test_predicted = model_.predict(X_test)\n",
    "        predictions = (test_predicted * std_Ys) + mean_Ys\n",
    "        target = (y_test * std_Ys) + mean_Ys\n",
    "        squareDeviation = computeSquareDeviation(predictions, target)\n",
    "        print(\"\\n\")\n",
    "        print(f,n_)\n",
    "        print(\"Time\",t_)\n",
    "        print(\"NRMSE\",np.sqrt(np.nanmean(squareDeviation)) / np.nanstd(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
