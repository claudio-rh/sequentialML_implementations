{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be3b14e-bad5-4332-861d-294af69e1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Claudio\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "path = '../datasets/'\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os_elmOTENIM import OS_ELM\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d543fb65-a435-4090-82dd-a792c36f9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,y,f):\n",
    "    \n",
    "    os_elm = OS_ELM(\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        loss='mean_squared_error',\n",
    "        activation=f,\n",
    "    )\n",
    "    \n",
    "    n_classes = n_output_nodes\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.3, random_state=123,shuffle = True)\n",
    "    \n",
    "    border = int(1.2 * n_hidden_nodes)\n",
    "    x_train_init = x_train[:border]\n",
    "    x_train_seq = x_train[border:]\n",
    "    t_train_init = t_train[:border]\n",
    "    t_train_seq = t_train[border:]\n",
    "    \n",
    "    start = timer ()\n",
    "    os_elm.init_train(x_train_init, t_train_init)\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        t_batch = t_train_seq[i:i+batch_size]\n",
    "        os_elm.seq_train(x_batch, t_batch)\n",
    "    \n",
    "    end = timer ()\n",
    "    time = end - start\n",
    "    #print(\"TIME\", end - start)\n",
    "    pred = os_elm.predict(x_test)\n",
    "    y_ = softmax(pred)\n",
    "    yy = []\n",
    "    for i in y_:\n",
    "        yy.append(np.argmax(i))\n",
    "    tt = []\n",
    "    for i in t_test:\n",
    "        tt.append(np.argmax(i))\n",
    "    #cm = confusion_matrix(tt, yy)\n",
    "    #sns.heatmap(cm, annot=True)\n",
    "    f1,a,p,r = metrics(tt,yy)\n",
    "    \n",
    "    return os_elm,time,f1,a,p,r\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def metrics(true,predicted):\n",
    "    p = precision_score(true,predicted,average='macro',labels=np.unique(predicted))\n",
    "    r = recall_score(true,predicted,average='macro')\n",
    "    a = accuracy_score(true,predicted)\n",
    "    f1 = f1_score(true,predicted,average='macro')\n",
    "\n",
    "    return f1,a,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6549a63e-83e0-4c40-9030-451de84b2da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden_nodes = 25 SIGMOID\n",
      "Tiempo: 0.04085804799998186\n",
      "F1: 0.8388290870513166\n",
      "A: 0.863111111111111\n",
      "P: 0.8375968241997653\n",
      "R: 0.8418823529411764\n",
      "\n",
      "n_hidden_nodes = 50 SIGMOID\n",
      "Tiempo: 0.03355611400001635\n",
      "F1: 0.8431044690603514\n",
      "A: 0.8666666666666667\n",
      "P: 0.8419821746880571\n",
      "R: 0.8458431372549019\n",
      "\n",
      "n_hidden_nodes = 100 SIGMOID\n",
      "Tiempo: 0.01185348200000135\n",
      "F1: 0.8418449197860964\n",
      "A: 0.8644444444444442\n",
      "P: 0.839852495543672\n",
      "R: 0.8463529411764705\n",
      "\n",
      "n_hidden_nodes = 25 RELU\n",
      "Tiempo: 0.04287053400000332\n",
      "F1: 0.9278939481386703\n",
      "A: 0.9377777777777777\n",
      "P: 0.9277059237059236\n",
      "R: 0.9345010893246186\n",
      "\n",
      "n_hidden_nodes = 50 RELU\n",
      "Tiempo: 0.03376826199999414\n",
      "F1: 0.9212547005333872\n",
      "A: 0.9319999999999999\n",
      "P: 0.920609599550776\n",
      "R: 0.9282396514161221\n",
      "\n",
      "n_hidden_nodes = 100 RELU\n",
      "Tiempo: 0.01275601399999232\n",
      "F1: 0.9184718632576073\n",
      "A: 0.9297777777777777\n",
      "P: 0.9159681184828244\n",
      "R: 0.9254117647058824\n"
     ]
    }
   ],
   "source": [
    "n_input_nodes = 4 #CANTIDAD DE ATRIBUTOS\n",
    "n_output_nodes = 3 #CANTIDAD DE CLASES\n",
    "\n",
    "\n",
    "dataset = \"iris.csv\"\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "map = {'setosa':0,'versicolor':1,'virginica':2}\n",
    "raw = raw.replace({'species':map})\n",
    "\n",
    "y = raw[\"species\"].to_numpy()\n",
    "raw.drop(['species'],inplace=True,axis=1)\n",
    "\n",
    "means = np.mean(raw,axis=0)\n",
    "stds = np.std(raw,axis=0)\n",
    "raw = (raw-means)/stds\n",
    "\n",
    "t = to_categorical(y, num_classes=3) \n",
    "X = raw.to_numpy()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
