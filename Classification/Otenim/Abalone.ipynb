{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea882a2-279d-4e59-8264-cb09773e8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Claudio\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "path = '../datasets/'\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os_elmOTENIM import OS_ELM\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75091999-6393-4222-837d-e79eb9cbbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,y,f):\n",
    "    \n",
    "    os_elm = OS_ELM(\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        loss='mean_squared_error',\n",
    "        activation=f,\n",
    "    )\n",
    "    \n",
    "    n_classes = n_output_nodes\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.33, random_state=123)\n",
    "    \n",
    "    border = int(1.2 * n_hidden_nodes)\n",
    "    x_train_init = x_train[:border]\n",
    "    x_train_seq = x_train[border:]\n",
    "    t_train_init = t_train[:border]\n",
    "    t_train_seq = t_train[border:]\n",
    "    \n",
    "    start = timer ()\n",
    "    os_elm.init_train(x_train_init, t_train_init)\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        t_batch = t_train_seq[i:i+batch_size]\n",
    "        os_elm.seq_train(x_batch, t_batch)\n",
    "    \n",
    "    end = timer ()\n",
    "    time = end - start\n",
    "    #print(\"TIME\", end - start)\n",
    "    pred = os_elm.predict(x_test)\n",
    "    y_ = softmax(pred)\n",
    "    yy = []\n",
    "    for i in y_:\n",
    "        yy.append(np.argmax(i))\n",
    "    tt = []\n",
    "    for i in t_test:\n",
    "        tt.append(np.argmax(i))\n",
    "    #cm = confusion_matrix(tt, yy)\n",
    "    #sns.heatmap(cm, annot=True)\n",
    "    f1,a,p,r = metrics(tt,yy)\n",
    "    \n",
    "    return os_elm,time,f1,a,p,r\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def metrics(true,predicted):\n",
    "    p = precision_score(true,predicted,average='macro',labels=np.unique(predicted))\n",
    "    r = recall_score(true,predicted,average='macro')\n",
    "    a = accuracy_score(true,predicted)\n",
    "    f1 = f1_score(true,predicted,average='macro')\n",
    "\n",
    "    return f1,a,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc4f90e-2383-4ad5-9f07-7d41bd134583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden_nodes = 25 SIGMOID\n",
      "Tiempo: 0.6760962879999943\n",
      "F1: 0.5113030287497051\n",
      "A: 0.5410732414793329\n",
      "P: 0.5233380266857351\n",
      "R: 0.53059307987043\n",
      "\n",
      "n_hidden_nodes = 50 SIGMOID\n",
      "Tiempo: 0.7038351919999946\n",
      "F1: 0.4947788475424277\n",
      "A: 0.5397244379985496\n",
      "P: 0.5173912876842643\n",
      "R: 0.5243852979549615\n",
      "\n",
      "n_hidden_nodes = 100 SIGMOID\n",
      "Tiempo: 0.738601898000004\n",
      "F1: 0.5074709453141414\n",
      "A: 0.5475562001450327\n",
      "P: 0.5230887907375849\n",
      "R: 0.5344111914663664\n",
      "\n",
      "n_hidden_nodes = 25 RELU\n",
      "Tiempo: 0.6755955599999948\n",
      "F1: 0.5319737184321249\n",
      "A: 0.5460333575054388\n",
      "P: 0.5314109305223302\n",
      "R: 0.541874655639882\n",
      "\n",
      "n_hidden_nodes = 50 RELU\n",
      "Tiempo: 0.683353098\n",
      "F1: 0.5371266314552772\n",
      "A: 0.549485134155185\n",
      "P: 0.5356160525501252\n",
      "R: 0.5454518277027358\n",
      "\n",
      "n_hidden_nodes = 100 RELU\n",
      "Tiempo: 0.7384896219999973\n",
      "F1: 0.537241228826264\n",
      "A: 0.5501087744742567\n",
      "P: 0.5355510618350895\n",
      "R: 0.5459525315230974\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Abalone.csv\"\n",
    "\n",
    "n_input_nodes = 8 #CANTIDAD DE ATRIBUTOS\n",
    "n_output_nodes = 3 #CANTIDAD DE CLASES\n",
    "\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "map = {'M':0,'F':1,'I':2}\n",
    "raw = raw.replace({'sex':map})\n",
    "\n",
    "y = raw[\"sex\"].to_numpy()\n",
    "raw.drop(['sex'],inplace=True,axis=1)\n",
    "t = to_categorical(y, num_classes=n_output_nodes) \n",
    "\n",
    "\n",
    "\n",
    "X = raw.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
