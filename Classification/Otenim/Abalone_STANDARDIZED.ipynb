{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea882a2-279d-4e59-8264-cb09773e8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Claudio\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "path = '../datasets/'\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os_elmOTENIM import OS_ELM\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75091999-6393-4222-837d-e79eb9cbbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,y,f):\n",
    "    \n",
    "    os_elm = OS_ELM(\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        loss='mean_squared_error',\n",
    "        activation=f,\n",
    "    )\n",
    "    \n",
    "    n_classes = n_output_nodes\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.33, random_state=123)\n",
    "    \n",
    "    border = int(1.2 * n_hidden_nodes)\n",
    "    x_train_init = x_train[:border]\n",
    "    x_train_seq = x_train[border:]\n",
    "    t_train_init = t_train[:border]\n",
    "    t_train_seq = t_train[border:]\n",
    "    \n",
    "    start = timer ()\n",
    "    os_elm.init_train(x_train_init, t_train_init)\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        t_batch = t_train_seq[i:i+batch_size]\n",
    "        os_elm.seq_train(x_batch, t_batch)\n",
    "    \n",
    "    end = timer ()\n",
    "    time = end - start\n",
    "    #print(\"TIME\", end - start)\n",
    "    pred = os_elm.predict(x_test)\n",
    "    y_ = softmax(pred)\n",
    "    yy = []\n",
    "    for i in y_:\n",
    "        yy.append(np.argmax(i))\n",
    "    tt = []\n",
    "    for i in t_test:\n",
    "        tt.append(np.argmax(i))\n",
    "    #cm = confusion_matrix(tt, yy)\n",
    "    #sns.heatmap(cm, annot=True)\n",
    "    f1,a,p,r = metrics(tt,yy)\n",
    "    \n",
    "    return os_elm,time,f1,a,p,r\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def metrics(true,predicted):\n",
    "    p = precision_score(true,predicted,average='macro',labels=np.unique(predicted))\n",
    "    r = recall_score(true,predicted,average='macro')\n",
    "    a = accuracy_score(true,predicted)\n",
    "    f1 = f1_score(true,predicted,average='macro')\n",
    "\n",
    "    return f1,a,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc4f90e-2383-4ad5-9f07-7d41bd134583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden_nodes = 25 SIGMOID\n",
      "Tiempo: 0.6989344419999725\n",
      "F1: 0.5415829185718093\n",
      "A: 0.5523422770123279\n",
      "P: 0.5392149911575246\n",
      "R: 0.5493441218968895\n",
      "\n",
      "n_hidden_nodes = 50 SIGMOID\n",
      "Tiempo: 0.7199280040000212\n",
      "F1: 0.5412957495937727\n",
      "A: 0.5510514865844816\n",
      "P: 0.5387235624850857\n",
      "R: 0.5480246433221424\n",
      "\n",
      "n_hidden_nodes = 100 SIGMOID\n",
      "Tiempo: 0.7704038180000226\n",
      "F1: 0.5409219712816498\n",
      "A: 0.5515155910079768\n",
      "P: 0.5387464563429197\n",
      "R: 0.5478065419412211\n",
      "\n",
      "n_hidden_nodes = 25 RELU\n",
      "Tiempo: 0.7050415660000272\n",
      "F1: 0.5417534291623729\n",
      "A: 0.5518346627991297\n",
      "P: 0.5402090075057122\n",
      "R: 0.5481091707709287\n",
      "\n",
      "n_hidden_nodes = 50 RELU\n",
      "Tiempo: 0.7095677499999783\n",
      "F1: 0.5502327301025614\n",
      "A: 0.559042784626541\n",
      "P: 0.5480370995816588\n",
      "R: 0.5557462247988115\n",
      "\n",
      "n_hidden_nodes = 100 RELU\n",
      "Tiempo: 0.7975307720000728\n",
      "F1: 0.5523898521005273\n",
      "A: 0.5614358230601886\n",
      "P: 0.5499920799278136\n",
      "R: 0.5580614183465358\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Abalone.csv\"\n",
    "\n",
    "n_input_nodes = 8 #CANTIDAD DE ATRIBUTOS\n",
    "n_output_nodes = 3 #CANTIDAD DE CLASES\n",
    "\n",
    "raw = pd.read_csv(path + dataset, header=0, skiprows=[1])\n",
    "map = {'M':0,'F':1,'I':2}\n",
    "raw = raw.replace({'sex':map})\n",
    "\n",
    "y = raw[\"sex\"].to_numpy()\n",
    "raw.drop(['sex'],inplace=True,axis=1)\n",
    "t = to_categorical(y, num_classes=n_output_nodes) \n",
    "\n",
    "means = np.mean(raw,axis=0)\n",
    "stds = np.std(raw,axis=0)\n",
    "raw = (raw-means)/stds\n",
    "\n",
    "X = raw.to_numpy()\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
