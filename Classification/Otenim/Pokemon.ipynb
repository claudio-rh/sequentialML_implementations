{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48f6f4b-4eb6-4361-b0e8-3225f2c089ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os_elmOTENIM import OS_ELM\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f6c49a-d29a-4193-94a5-e912f24069cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,y,f):\n",
    "    \n",
    "    os_elm = OS_ELM(\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        loss='mean_squared_error',\n",
    "        activation=f,\n",
    "    )\n",
    "    \n",
    "    n_classes = n_output_nodes\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.33, random_state=123)\n",
    "    \n",
    "    border = int(1.2 * n_hidden_nodes)\n",
    "    x_train_init = x_train[:border]\n",
    "    x_train_seq = x_train[border:]\n",
    "    t_train_init = t_train[:border]\n",
    "    t_train_seq = t_train[border:]\n",
    "    \n",
    "    start = timer ()\n",
    "    os_elm.init_train(x_train_init, t_train_init)\n",
    "    \n",
    "    batch_size = 1\n",
    "    \n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        t_batch = t_train_seq[i:i+batch_size]\n",
    "        os_elm.seq_train(x_batch, t_batch)\n",
    "    \n",
    "    end = timer ()\n",
    "    time = end - start\n",
    "    #print(\"TIME\", end - start)\n",
    "    pred = os_elm.predict(x_test)\n",
    "    y_ = softmax(pred)\n",
    "    yy = []\n",
    "    for i in y_:\n",
    "        yy.append(np.argmax(i))\n",
    "    tt = []\n",
    "    for i in t_test:\n",
    "        tt.append(np.argmax(i))\n",
    "    #cm = confusion_matrix(tt, yy)\n",
    "    #sns.heatmap(cm, annot=True)\n",
    "    f1,a,p,r = metrics(tt,yy)\n",
    "    \n",
    "    return os_elm,time,f1,a,p,r\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def metrics(true,predicted):\n",
    "    p = precision_score(true,predicted,average='macro',labels=np.unique(predicted))\n",
    "    r = recall_score(true,predicted,average='macro')\n",
    "    a = accuracy_score(true,predicted)\n",
    "    f1 = f1_score(true,predicted,average='macro')\n",
    "\n",
    "    return f1,a,p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b627d27-94ae-423d-8ccc-289b8f9a3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden_nodes = 25 SIGMOID\n",
      "Tiempo: 0.06397868000000471\n",
      "F1: 0.3161852099766744\n",
      "A: 0.4232258064516129\n",
      "P: 0.43536417968302665\n",
      "R: 0.38899825783972125\n",
      "\n",
      "n_hidden_nodes = 50 SIGMOID\n",
      "Tiempo: 0.057798778000002354\n",
      "F1: 0.37895863684815756\n",
      "A: 0.4427956989247312\n",
      "P: 0.44356598953940723\n",
      "R: 0.41981029810298104\n",
      "\n",
      "n_hidden_nodes = 100 SIGMOID\n",
      "Tiempo: 0.04431632200000195\n",
      "F1: 0.4347193021638839\n",
      "A: 0.4726881720430108\n",
      "P: 0.46193745406753695\n",
      "R: 0.45474061169183116\n",
      "\n",
      "n_hidden_nodes = 25 RELU\n",
      "Tiempo: 0.06666901999999482\n",
      "F1: 0.41315314475823106\n",
      "A: 0.4901075268817204\n",
      "P: 0.43472891002694375\n",
      "R: 0.45889179248935347\n",
      "\n",
      "n_hidden_nodes = 50 RELU\n",
      "Tiempo: 0.059252058000004125\n",
      "F1: 0.3961095691481041\n",
      "A: 0.478494623655914\n",
      "P: 0.4066573362309343\n",
      "R: 0.4455671699574138\n",
      "\n",
      "n_hidden_nodes = 100 RELU\n",
      "Tiempo: 0.044944816000005404\n",
      "F1: 0.37029804428844665\n",
      "A: 0.46193548387096767\n",
      "P: 0.3697490296733156\n",
      "R: 0.427045102593883\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Pokemon.csv\"\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "data = pd.read_csv(path + dataset)\n",
    "\n",
    "\n",
    "n_input_nodes = 10 #CANTIDAD DE ATRIBUTOS\n",
    "n_output_nodes = 3 #CANTIDAD DE CLASES\n",
    "\n",
    "\n",
    "data = data.set_index(\"#\")\n",
    "\n",
    "d = {}\n",
    "for i in range(len(data[\"Type 2\"].unique())):\n",
    "  d[data[\"Type 2\"].unique()[i]] = i + 1\n",
    "data = data.drop(columns = [\"Name\"])\n",
    "data = data.fillna(0)\n",
    "data[\"Type 2\"] = data[\"Type 2\"].replace(d)\n",
    "\n",
    "\n",
    "data_balanced = data[(data[\"Type 1\"] == \"Water\") | (data[\"Type 1\"] == \"Normal\") | (data[\"Type 1\"] == \"Grass\")]\n",
    "m = {'Water':0,'Normal':1,'Grass':2}\n",
    "data_balanced = data_balanced.replace({'Type 1':m})\n",
    "y = data_balanced[\"Type 1\"].to_numpy()\n",
    "data_balanced.drop(['Type 1'],inplace=True,axis=1)\n",
    "\n",
    "\n",
    "X = data_balanced.to_numpy()\n",
    "t = to_categorical(y, num_classes=n_output_nodes) \n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"sigmoid\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"SIGMOID\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))\n",
    "\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "tiempo = []\n",
    "f1 = []\n",
    "a = []\n",
    "p = []\n",
    "r = []\n",
    "\n",
    "for i in range(50):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    model,t_,f1_,a_,p_,r_ = Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,t,\"relu\")\n",
    "    tiempo.append(t_)\n",
    "    f1.append(f1_)\n",
    "    a.append(a_)\n",
    "    p.append(p_)\n",
    "    r.append(r_)\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes , \"RELU\")\n",
    "print(\"Tiempo:\",np.mean(tiempo))\n",
    "print(\"F1:\",np.mean(f1))\n",
    "print(\"A:\",np.mean(a))\n",
    "print(\"P:\",np.mean(p))\n",
    "print(\"R:\",np.mean(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
