{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46904aa8-74f0-4d7f-bcd2-bb811447ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "path = '../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653ff86c-28fb-4484-ad14-fe9fdf18445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(true,predicted):\n",
    "    #CM = confusion_matrix(predicted, true)\n",
    "    p = precision_score(true,predicted,average='macro',zero_division=1)\n",
    "    r = recall_score(true,predicted,average='macro')\n",
    "    a = accuracy_score(true,predicted)\n",
    "    f1 = f1_score(true,predicted,average='macro')\n",
    "    \n",
    "    \n",
    "    print(\"F1 =\",f1)\n",
    "    print(\"Accuracy =\",a)\n",
    "    print(\"Precision =\",p)\n",
    "    print(\"Recall =\",r)\n",
    "\n",
    "\n",
    "def Aamirg(X,y,n_input_nodes,n_hidden_nodes,n_output_nodes,f):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,shuffle = True)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(n_input_nodes, activation=f, input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(n_hidden_nodes, activation=f))\n",
    "    model.add(layers.Dense(n_output_nodes,activation='softmax'))\n",
    "    #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    batch = 1\n",
    "    opt = optimizers.rmsprop_v2.RMSprop(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    start = timer()\n",
    "    model.fit(X_train,\n",
    "    y_train,\n",
    "    epochs=int( len(X_train) / batch),\n",
    "    batch_size= batch,\n",
    "    validation_data=(X_test,y_test),\n",
    "    #callbacks=[callback],\n",
    "    verbose = False)\n",
    "    end = timer()\n",
    "    print(\"TIME\",end-start)\n",
    "    pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    tt = np.argmax(y_test, axis=-1)\n",
    "#     cm = confusion_matrix(tt, pred)\n",
    "#     sns.heatmap(cm, annot=True)\n",
    "    metrics(tt,pred)   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c28f552-11ec-4718-9fa9-2b769897eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden_nodes = 25 SIGMOID\n",
      "TIME 18.05598759999998\n",
      "F1 = 0.18974358974358974\n",
      "Accuracy = 0.3978494623655914\n",
      "Precision = 0.7992831541218638\n",
      "Recall = 0.3333333333333333\n",
      "\n",
      "n_hidden_nodes = 50 SIGMOID\n",
      "TIME 19.111613399999897\n",
      "F1 = 0.25866666666666666\n",
      "Accuracy = 0.43010752688172044\n",
      "Precision = 0.7363636363636363\n",
      "Recall = 0.36241956241956247\n",
      "\n",
      "n_hidden_nodes = 100 SIGMOID\n",
      "TIME 19.623854800000117\n",
      "F1 = 0.20973298880275626\n",
      "Accuracy = 0.40860215053763443\n",
      "Precision = 0.8007246376811595\n",
      "Recall = 0.3428571428571428\n",
      "\n",
      "n_hidden_nodes = 25 RELU\n",
      "TIME 19.178062100000034\n",
      "F1 = 0.45603402445507707\n",
      "Accuracy = 0.5698924731182796\n",
      "Precision = 0.7254901960784315\n",
      "Recall = 0.4961818961818962\n",
      "\n",
      "n_hidden_nodes = 50 RELU\n",
      "TIME 19.358289000000013\n",
      "F1 = 0.4933595211372989\n",
      "Accuracy = 0.5483870967741935\n",
      "Precision = 0.5030030030030029\n",
      "Recall = 0.4997854997854998\n",
      "\n",
      "n_hidden_nodes = 100 RELU\n",
      "TIME 19.123272000000043\n",
      "F1 = 0.5033068783068783\n",
      "Accuracy = 0.5483870967741935\n",
      "Precision = 0.5084533038021409\n",
      "Recall = 0.5056199056199057\n"
     ]
    }
   ],
   "source": [
    "#POKEMON DATASET\n",
    "dataset = \"Pokemon.csv\"\n",
    "data = pd.read_csv(path + dataset)\n",
    "\n",
    "\n",
    "n_input_nodes = 10 #CANTIDAD DE ATRIBUTOS\n",
    "n_output_nodes = 3 #CANTIDAD DE CLASES\n",
    "\n",
    "\n",
    "data = data.set_index(\"#\")\n",
    "\n",
    "d = {}\n",
    "for i in range(len(data[\"Type 2\"].unique())):\n",
    "  d[data[\"Type 2\"].unique()[i]] = i + 1\n",
    "data = data.drop(columns = [\"Name\"])\n",
    "data = data.fillna(0)\n",
    "data[\"Type 2\"] = data[\"Type 2\"].replace(d)\n",
    "\n",
    "\n",
    "data_balanced = data[(data[\"Type 1\"] == \"Water\") | (data[\"Type 1\"] == \"Normal\") | (data[\"Type 1\"] == \"Grass\")]\n",
    "m = {'Water':0,'Normal':1,'Grass':2}\n",
    "data_balanced = data_balanced.replace({'Type 1':m})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = data_balanced[\"Type 1\"].to_numpy()\n",
    "data_balanced.drop(['Type 1'],inplace=True,axis=1)\n",
    "\n",
    "means = np.mean(data_balanced,axis=0)\n",
    "stds = np.std(data_balanced,axis=0)\n",
    "raw = (data_balanced-means)/stds\n",
    "\n",
    "X = data_balanced.to_numpy()\n",
    "X = np.asarray(X).astype('float32')\n",
    "t = to_categorical(y, num_classes=n_output_nodes) \n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"SIGMOID\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"sigmoid\")\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"SIGMOID\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"sigmoid\")\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"SIGMOID\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"sigmoid\")\n",
    "\n",
    "n_hidden_nodes = 25\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"RELU\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"relu\")\n",
    "\n",
    "n_hidden_nodes = 50\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"RELU\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"relu\")\n",
    "\n",
    "n_hidden_nodes = 100\n",
    "print(\"\\nn_hidden_nodes =\",n_hidden_nodes,\"RELU\")\n",
    "model = Aamirg(X,t,n_input_nodes,n_hidden_nodes,n_output_nodes,\"relu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
